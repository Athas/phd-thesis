\chapter{Conclusions and Future Work}
\label{chap:conclusions}

We have presented a fully automatic optimizing compiler for Futhark, a
pure functional array language.  Futhark is a simple language that
supports just a few core concepts, yet is more expressive than prior
parallel languages of similar performance, in particular by supporting
nested parallelism.  While more flexible parallel languages exist
(notably NESL), these have not yet been shown to obtain good GPU
performance in practice.

We have demonstrated a combination of imperative and functional
concepts by supporting in-place updates with safety guaranteed by
uniqueness types rather than complicated index-based analysis.  We
support not just efficient top-level imperative code with in-place
updates, but also sequential code nested inside parallel constructs,
all without violating the functional properties on which we depend for
safe parallel execution.

We have also shown how size-dependent array types can be inferred from
a size-agnostic source program, via a combination of type-driven rules
and function slicing.  Our slicing technique results in neglible
overhead in practice.

By introducing novel parallel streaming constructs, we provide better
support for efficient sequential execution of excess parallelism than
is possible with the classical parallel combinators.  We have also
shown how these constructs permit highly general fusion rules, in
particular permitting sequential fusion without losing the potential
for parallel execution.

All of these build up to our primary result, the moderate flattening
algorithm, which allows the efficient exploitation of easily
accessible ``common case'' parallelism.  The moderate flattening
algorithm sequentialises excess parallelism while keeping intact the
high-level invariants provided by the original parallel and purely
functional formulation, which permits further locality-of-reference
optimisations.  We have demonstrated this capability by showing how to
automatically repair some cases of non-coalesced memory accesses, as
well as performing simple block tiling of loops.  We argue that the
moderate flattening algorithm can be developed further into a
\textit{gradual flattening algorithm}, which uses multi-versioned code
to exploit a varying amount of parallelism of the program, dependent
on the characteristics of the input data encountered at runtime.

To support our claims, we have validated our approach on $21$
benchmark programs, which are compiled to GPU code via
OpenCL. Compared to reference implementations, the performance ranges
from $\times0.21$ slowdown to $\times13$ speedup, and is competitive
on average.
%
Our results show that while the ease of high-level structural
transformation permitted by a functional language is powerful,
attention must still be paid to low-level issues such as communication
costs and memory access patterns.

We have made the developed compiler and all benchmark programs freely
available for reproduction, study, or further development.

\section{Limitations and Future Work}

The primary limitation of Futhark as a language is the lack of support
for irregular arrays.  Some problems, such as graph algorithms, are
naturally irregular, and transforming them to a regular formulation is
tedious and error-prone.  Worse, such transformation is essentially
manual flattening, which tends to result in code that is hard for the
compiler to analyse and optimise.  It remains to be seen how we can
either modify the algorithms in question to exhibit less irregularity,
or extend Futhark with lightweight support for some cases of irregular
parallelism, without sacrificing the ability of the compiler to
generate efficient code.  After all, Futhark's entire \textit{raison
  d'Ãªtre} is performance---there are already many functional languages
that are far more expressive, so improving flexibility at great cost
in runtime performance is not a goal.

However, even with the current language, irregularity still rears its
ugly head for the compiler.  It is not hard to write a program that,
although it uses only regular arrays, implicitly expresses irregular
\textit{parallelism}, which cannot in general be handled by our
current approach.  The reason is that we expect to be able to
pre-allocate memory before entering GPU kernels, but it is not hard to
write a program in which the size of intermediate arrays is
thread-variant.  For example, consider the following expression.
\begin{lstlisting}
map (\i -> reduce (+) 0 (iota i)) is
\end{lstlisting}
\noindent The size of the array produced by \lstinline{iota i} may
differ for each element of the array \texttt{is}, which means the
total memory requirement of the \kw{map} cannot be immediately known.
The problem has multiple solutions.  In the most general case, we can
apply full flattening---this removes all forms of irregularity, but
the overhead can be significant.  In other cases, a slicing approach
can be used.  For example, we can precompute the total memory
required, allocate one large slab of memory, and use a \kw{scan} to
compute an offset for each iteration of the \kw{map}:
\begin{lstlisting}
let os = scan (+) 0 is
in map (\(i,o) ->
          -- iota i located at offset 'o'
          -- in some memory block.
          reduce (+) 0 (iota i))
       (zip is os)
\end{lstlisting}

This is not a language issue---our sequential compiler pipeline is
able to compile any valid Futhark program to sequential code---but a
limitation in our compilation strategy for parallel code.  Our
strategy is to focus on development a technique for exploiting
``common case'' parallelism efficiently, and only later extend it to
support more exotic cases.  This work will take the form of a
\textit{gradual flattening} algorithm that employes multi-versioned
code as discussed in \cref{sec:multi-versioned-code}.

Various other opportunities for improvements have been noted
throughout the thesis.  These are summarised below.

\begin{description}
\item[Provide a language mechanism for reasoning about irregularity:]
  As discussed above, irregularity is one of the main weak points of
  Futhark's approach.  Even when we add support for irregular
  parallelism, it is likely that irregular programs will run slower
  than corresponding regular programs.  It would be useful to come up
  with a language-based model for reasoning about regularity of
  parallelism, in the same way that size annotations already let us
  reason about the regularity of arrays.

\item[Support tail-recursion directly:] Futhark does not directly
  support tail-recursion, which is mostly due to concerns about
  implementation simplicity.  Instead, the programmer is required to
  manually express the tail-recursive functions using the \kw{loop}
  syntax.  It would be useful if the Futhark compiler could
  automatically perform this conversion, and report an error on
  non-tail recursive functions.  Ideally, this would also support
  mutually tail-recursive functions.

\item[Support higher-order functions:] While higher-order functions
  can be imitated using the module system, as shown on
  \cref{fig:faking-hof}, this is rather verbose.  It would be useful
  if higher-order functions could be used directly, with type rules
  guaranteeing that they can be efficiently compiled away early in the
  compilation process, using a defunctionalisation transformation.  We
  believe that it can be guaranteed that the result of such a
  transformation is efficient (contains no branches or indirect
  accesses) if a function is never used as a \kw{loop} parameter,
  returned from a branch, or put into an array.  However, it is not
  yet clear how higher-order functions would interact with size
  annotations, or with the uniqueness type system.

\item[Iteration analysis when transforming data for coalesced access:]
  \Cref{sec:automatic-coalescing} describes a transformation that
  changes the in-memory representation of arrays in order to ensure
  that they will be accessed efficiently by the GPU.  However, it
  relies on the simplifying assumption that if an individual GPU
  thread takes a slice of an array, then that slice will be traversed
  sequentially.  This is not necessarily true.  The compiler could
  instead perform an actual analysis to determine how the thread
  accesses memory, and represent the array in exactly the form that
  leads to coalesced memory access patterns.  Since the sequential
  looping operations performed by the thread are (potentially) still
  represented using SOACs, the compiler has enough high-level
  information available to perform the analysis without getting bogged
  down in the complicated index analysis discussed in
  \cref{sec:related-automatic-par}.

\item[Improving memory management for stencils:] As discussed in
  \cref{sec:rodinia}, the memory management strategy used by the
  Futhark compiler exhibits pathological behaviour for stencil
  programs (or more generally, any program with an outer sequential
  convergence loop), in which an extra copy of the result is
  performed.  This is an artifact of the \textit{double buffering}
  transformation that the Futhark compiler performs in order to move a
  memory allocation out of the loop.  This transformation should be
  improved to perform pointer swapping in the conventional way, rather
  than copying the result.

\item[Parallel operators for certain irregular problems:]
  \Cref{sec:bfs-benchmarking} shows an irregular problem
  (breadth-first search) in which the parallel operators provided by
  Futhark are insufficient for permitting the compiler to generate
  code similar to what a human would write by hand.  It is not clear
  whether a new source-language feature is required, or whether we
  could simply augment the core language with a new ``streaming
  \kw{scatter}'' construct that is produced by fusion.
\end{description}

As the Futhark compiler is publicly available free software developed
in the open, we naturally encourage all interested readers to
contribute in solving the above (and other) problems:

\begin{center}
  \url{https://github.com/diku-dk/futhark}
\end{center}

Happy hacking!

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
