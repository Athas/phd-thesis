\renewcommand{\sp}{\quad}
\newcommand{\ft}{\phi}
\newcommand{\fts}{\varphi}
\newcommand{\tty}{\rho}
\newcommand{\utty}{\hat{\rho}}
\newcommand{\sembox}[1]{\hfill \normalfont \mbox{\fbox{\(#1\)}}}
\newcommand{\sempart}[2]{\textrm{\textit{#1 \sembox{#2}}}}
\newcommand{\vdb}{\vd_\textrm{b}}
\newcommand{\vde}{\vd_\textrm{e}}
\newcommand{\vdp}{\vd_\textrm{p}}
\newcommand{\vdhp}{\vd_{\hat{\textrm{p}}}}
\newcommand{\vdP}{\vd_\textrm{P}}
\newcommand{\vda}{\vd_\textrm{a}}
\newcommand{\fracc}[2]{\begin{eqnarray} \inference{#1
    }{#2}\end{eqnarray}}
\newcommand{\fraccn}[2]{\refstepcounter{equation}\mbox{$\inference{#1}{#2}$}~(\arabic{equation})}
\newcommand{\fraccc}[2]{\mbox{$\frac{\begin{array}{c} #1 \end{array}}{\begin{array}{c} #2 \end{array}}$}}
\newcommand{\fn}{\ensuremath{\lambda}}
\newcommand{\Fn}[3]{\fn#2:~#1~\rightarrow #3}
\newcommand{\FnU}[2]{\fn#1~\rightarrow #2}
\newcommand{\ubar}[1]{\underline{#1}}
\newcommand{\utau}{\hat{\tau}}
\newcommand{\etau}{\ubar{\tau}}
\newcommand{\opty}{\ubar{\phi}}
\newcommand{\Fun}[4]{\mbox{\lstinline[mathescape]!let\ #1\ #2\ :\ #3 =\ #4!}}

\chapter{Overview and Uniqueness Types}

This chapter contains three primary elements: First, an overview of
the compiler design, with an emphasis on how the program is
transformed as it proceeds through the pipeline
(\cref{sec:compiler-design}).  Second, a simplified Futhark core
language that will be used in the following chapters to describe the
operations performed by the Futhark compiler
(\cref{sec:futhark-core-ast}).  Third, a formalisation of the
uniqueness type system expressed on the core language
(\cref{sec:uniqueness-formalism}).

The simplification engine encompasses well established optimisations
such as inlining, copy propagation, constant folding,
common-subexpression elimination, dead-code elimination, and hoisting
of invariant terms out of recurrences in loops and SOACs.  The
simplification rules are critical for optimising the result of
higher-level optimisations, such as producer-consumer
fusion~\cite{henriksen2014exploiting,henriksen2013t2}, hoisting, and
size analysis, which is the subject of
Chapter~\ref{chap:size-analysis}.  For example, size analysis is
implemented via high-level transformation rules that only guarantee
that the asymptotic complexity (in number of operations) of the
original program is preserved, but rely on the simplification engine
to reduce the overhead to be negligible in the common case.

\section{Compiler Design}
\label{sec:compiler-design}

The Futhark compiler is implemented in Haskell, and is designed as a
conventional syntax-directed translator.  The compiler is comprised as
a number of \textit{passes}, which can be seen as functions that
accept a program as input, and produce a program as output.  Some
passes perform rewrites of a program in some representation, while
other passes lower the program to a more specialised or lower-level
representation.

The compiler contains two different compiler pipelines; one for
generating a sequential program, and one for generating a program with
parallel code.  Parallelism in the generated code is expressed as
OpenCL~\cite{Stone:2010:OPP:622179.1803953} kernels.  While OpenCL is
a hardware-agnostic API, and we generate portable OpenCL code, many of
the optimisations we perform make assumptions that are specific to
GPUs.  We might not achieve desired performance if we executed the
generated OpenCL code on, for example, FPGAs or other such exotic
platforms.  We have, however, noted decent performance on multicore
CPUs, but this is not a direction we shall investigate in this thesis.

The initial passes of the sequential and parallel pipelines are
identical, but they differ after a certain point.  In this section,
and the thesis as a whole, we will focus on the parallel compilation
pipeline, as it is by far the more complicated of the two.  The
intermediate representation used by Futhark is typed, and to ensure
robustness, full type-checking (including verifying safety of in-place
updates) is performed between all compiler passes.  The type checking
rules become more lenient as the representation is gradually lowered,
and the later stages perform only cursory checking.  This
type-checking carries a significant compilation overhead
(approximately $20\%$), so we expect to disable it for production
releases of the compiler.

The pipeline proceeds with the following passes in order as follows:

\begin{description}
\item[Internalisation and Desugaring] The source Futhark language is
  translated into the core language (\cref{sec:futhark-core-ast}).  In
  particular, modules and polymorphic functions are removed through
  specialisation (outside the scope of the thesis), all tuples are
  flattened, and arrays of tuples are transformed into tuples of
  arrays, as shown on \ref{fig:calc-tuple-transform}.  This is also
  the pass where where size inference is performed
  (\cref{chap:size-analysis}).

\item[Inlining and Dead Function Removal] All functions are
inlined.  As the Futhark language presently does not support recursive
functions, this is always possible.  This may result in significant
growth in code size, and so future work should investigate more
conservative approaches.  Inlining is critical to making subsequent
optimisations possible, however.  On GPUs, our main target platform,
all functions inside kernels are automatically inlined in any case, so
we do not lose much by inlining at the Futhark-level sas well.

\item[SOAC Fusion] SOACs in a producer-consumer relationship, or
simply adjacent and looping over arrays of identical size, are fused
(\cref{chap:fusion}).

\item[Kernel Extraction] A moderate flattening algorithm is
applied to the program, which transforms nests of SOACS into
flat-parallel kernels (\cref{chap:kernel-extraction}).  The kernels
produced here are not yet low-level GPU kernels, but a higher-level
representation that still abstracts many details, in particular issues
of memory allocation.  Nested parallelism is gone after this pass.

\item[Coalescing Fixes] The kernels generated in the previous
pass are inspected, and non-coalesced array access patterns are
resolved by semantically transposing the arrays in question
(\cref{sec:automatic-coalescing}).

\item[Loop Tilng] Loop tiling is performed inside the generated
kernels (\cref{sec:automatic-tiling}).  This is the last pass we
discuss in detail in this thesis---the remainder are concerned with
various technical minutiae, which, while extremely time-consuming and
challenging to implement, are of lesser scientific importance.

\item[Memory Allocation] Explicit allocations are inserted in
the program, in a scheme similar to region
inference~\cite{mlkit_retrospective}.  Every array becomes associated
with a ``memory block'', the allocation of which can be hoisted out of
the recurrence or branch where the array itself is constructed.  To
handle cases where pre-allocation is not possible (such as a loop
where the array size changes for every iteration), the
existential-types mechanism also employed for size inference
(\cref{chap:size-analysis}) is used.  The ability for the compiler to
manipulate memory allocations as program constructs is important.  We
use this to arrange the program such that all memory is pre-allocated
before entering GPU kernels, inside which allocation is not supported.

\item[Double Buffering] We perform double buffering to enable
the hosting of memory allocations out of loops (in particular loops
that are inside parallel kernels).  For technical reasons, we
currently do not perform double buffering in the usual way, with
pointer swapping, but instead insert extra copies for every iteration
of the loop.  In \cref{sec:rodinia} we shall see an example where this
significantly impacts our performance.

\item[Memory Expansion] It is not safe to naively hoist
allocations out of parallel kernels.  When hoisting such allocations,
we first have to perform \textit{expansion}, such that one per-thread
private allocation of $b$ bytes becomes one shared allocation of
$n\times{}b$ bytes, where $n$ is the number of threads.  This requires
all allocations to be at the top level of kernels, and for their size
to be expressible in terms of (or at least bounded by) variables whose
value is known before the kernel.

\item[Imperative IR Code Generation] The flat-parallel Futhark
program with explicit allocations is transformed into a low-level
imperative intermediate representation (IR).  This IR is similar to C,
but significantly simpler, and much more explicit.  No optimisations
are performed on this representation.  The IR has special constructs
for representing GPU kernels, whose bodies are also expressed with the
imperative IR.  This pass fails if any allocations remain inside
parallel kernels.

\item[Final Code Generation] The imperative IR is transformed
into host-level (CPU) code and actual OpenCL kernels.  The host-level
code is either C or Python, with calls to the OpenCL library, while
OpenCL kernels are in OpenCL C (a restricted dialect of C).  We write
the result to one or more files, and, depending on the compilation
options, may invoke a C compiler to generate an executable.
\end{description}

\subsection{Simplification Passes}

The preceding list of passes is incomplete.  Between almost every
pass, we perform a range of simplifications and conventional
optimisations.  There are too many in number, and too individually
uninteresting, to be discussed in detail, but a few deserve mention:

\begin{description}
\item[Copy propagation, constant folding, and CSE:] The usual bevy of
  of scalar optimisations is performed, with range analysis and
  propagation performed to support the elimination of (some) bounds-
  and size checks.
\item[Aggressive hoisting:] The Futhark compiler aggressively hoists
  expressions out of loops and branches, where possible and safe.
  Care is taken to avoid hoisting potentially expensive constructs out
  of branches.
\item[Dead code removal:] We remove not merely expressions whose
  results are never used, but also rewrite expressions where only part
  of the result is used.  Consider for example an \kw{if} that returns
  a pair, where only one component of the pair is subsequently used.
\item[Removal of single-iteration loops and SOACs:] Any loop with a
  single iteration, or a SOAC whose input array has a constant size of
  $1$, can be trivially substituted with its body.  This is used to
  enable efficient sequentialisation (see \cref{sec:streamseq-fusion}
  for an example).
\item[Un-existentialisation:] As we shall see in
  \cref{chap:size-analysis}, Futhark uses an existential type system
  with size-dependent types.  Simplification rules are used for making
  existential sizes concrete where possible.
\end{description}

Most of the simplifications are performed by a general simplification
engine, which traverses the program and applies a collection of
rewrite rules to every expression.  The process is repeated until a
fixed point is reached.  This approach is fairly similar to the one
used by the Glasgow Haskell Compiler (GHC)~\cite{jones2001playing}.
The main difference is that in GHC the rules are expressed as
user-provided equalities, but the simplification rules in Futhark are
hardwired into the compiler in the form of monadic Haskell functions.
This allows the Futhark rewrite rules to be significantly more
powerful, as they can inspect the surrounding environment, but they
are not user-extensible.  As an example, \cref{fig:removeDeadMapping}
defines a rule that removes results of a \kw{map} that are not used
subsequently.  This rule depends on information about what happens
\textit{after} the expression, and is thus applied during a bottom-up
traversal.  This is the sole exception to our general policy of not
showing compiler implementation code in this thesis.

\begin{figure}
\begin{lstlisting}[basicstyle=\small\ttfamily,language=Haskell]
removeDeadMapping :: (MonadBinder m,
                      Op (Lore m) ~ SOAC (Lore m))
                     => BottomUpRule m
removeDeadMapping (_, used)
                  (Let pat _ (Op (Map cs width fun arrs))) =
  let ses = bodyResult $ lambdaBody fun
      isUsed (bindee, _, _) =
        (`UT.used` used) $ patElemName bindee
      (pat',ses', ts') =
        unzip3 $ filter isUsed $
        zip3 (patternElements pat) ses $ lambdaReturnType fun
      fun' = fun { lambdaBody =
                     (lambdaBody fun) { bodyResult = ses' }
                 , lambdaReturnType = ts'
                 }
  in if pat /= Pattern [] pat'
     then letBind_ (Pattern [] pat') $
            Op $ Map cs width fun' arrs
     else cannotSimplify
removeDeadMapping _ _ = cannotSimplify
\end{lstlisting}
  \caption{An example of a simplification rule from the Futhark
    compiler (slightly reformatted for presentation purposes).  This
    rule removes \kw{map} results that are never used.}
  \label{fig:removeDeadMapping}
\end{figure}

\section{Abstract Syntax of the Core IR}
\label{sec:futhark-core-ast}

This section describes the abstract syntax of a simplified form of the
Futhark intermediate representation (IR).

\subsection{Notation for sequences}

Whenever $z$ is an object of some kind, we write $\seq{z}$ to range
over sequences of objects of this kind. When we want to be explicit
about the size of a sequence $\seq{z} = z_0,\cdots,z_{(n-1)}$, we
often write it on the form $\nseq{z}{n}$ and we write $z,\seq{z}$ to
denote the sequence $z,z_0,\cdots,z_{(n-1)}$.  Depending on context,
the elements of the sequence or may not have separators, or be merely
juxtaposed.  For example, we may use the same notation to shorten a
function application
\[
  f~\nseq{v}{n} \equiv f~v_{1}~\cdots~v_{n}
\]
or a tuple
\[
  (\nseq{v}{n}) \equiv (v_{1}, \ldots, v_{n})
\]
or a function type
\[
  \nseq{\tau}{n} \rightarrow \tau_{n+1} \equiv \tau_{1} \rightarrow \cdots \rightarrow \tau_{n} \rightarrow \tau_{n+1}.
\]
It is always clear from the context which separator (if any) is
intended.  On occasion we use more complicated sequences, where not
all terms under the bar are variant.  In this case, the variant term
is subscripted with $i$.  For example,
\[
  (\nseq{[d]v_{i}}{n}) = ([d]v_{1}, \ldots, [d] v_{n})
\]
and
\[
  (\nseq{[d_{i}]v_{i}}{n}) = ([d_{1}]v_{1}, \ldots, [d_{n}] v_{n})
\]

\begin{figure*}
$$
  \begin{array}{lrlr}
    f & ::= & \textbf{id} & \mbox{(Function names)}\\
    d,x,y,z & ::= & \textbf{id} & \mbox{(Variable names)}\\
    c & ::= & \textbf{const} & \mbox{(Constant value)}\\
    t &::=& \texttt{bool}~|~\texttt{i32}~|~\texttt{f32}~|~... & \mbox{(Built-in types)} \\
    \\
    \tau & ::= & \mbox{\texttt{t} ~ $|$ ~ \texttt{[]$\tau$}} & \mbox{(Scalar/array type)} \\
    \utau & ::= & \mbox{$\tau$ ~ $|$ ~ \texttt{*}$\tau$} & \mbox{(Nonunique/Unique type)} \\
    \tty  & ::=   & (\tau_1, \ldots, \tau_n) & \mbox{(Tuple types)}\\
    \utty  & ::=   & (\utau_1, \ldots, \utau_n) & \mbox{(Nonunique/Unique tuple types)}\\
    \ft & ::= & \tty_1 \rightarrow \cdots \rightarrow \tty_n & \mbox{(Function type)}\\
    \\
    p & ::= & (x_{1} : \tau_{1})~\ldots~(x_{n} : \tau_{n})  & \mbox{(\lstinline{let} or $\lambda$ pattern)} \\
    \hat{p} & ::= & (x_{1} : \utau_{1})~\ldots~(x_{n} : \utau_{n})  & \mbox{(Function pattern)} \\
    \\
    fun & ::= & \mbox{\Fun{$f$}{$\hat{p}$}{$\utau$}{$e$}} ~~& ~~\mbox{(Named function)} \\
    P & ::= & \mbox{$\epsilon$ ~ $|$ ~ $fun$ ~ $P$} & \mbox{(Program)} \\
    \\
    e & ::= & \mbox{\texttt{($x_{1},\ldots,x_{n}$)}} & \mbox{($n$-tuple)}\\
      & | & \mbox{\lstinline[mathescape]!let\ $p$ =\ $e$ in\ $b$!} & \mbox{(Let binding)}\\
      & | & k & \mbox{(Constant)} \\
      & | & x & \mbox{(Variable)} \\
      & | & e \odot{} e & \mbox{(Scalar binary operator)}\\
      & | & \mbox{\lstinline[mathescape]!if\ $e$ then\ $e$ else\ $e$!} & \mbox{(Branch)} \\
      & | & \mbox{\texttt{$x$[$x_{1},\ldots,x_{n}$]}} & \mbox{(Array indexing)}\\
      & | & \mbox{\lstinline[mathescape]!$x$ with [$e_{1},\ldots,e_{n}$] <-\ $e$!} &\mbox{(In-place update)}\\
      & | & \mbox{\lstinline[mathescape]!loop ($\hat{p}$)=($x_{1},\ldots,x_{n}$)!}  &  \mbox{(Loop)} \\
      &   & \mbox{\lstinline[mathescape]!\ for\ $x$ <\ $x$ do\ $e$!}\\
      & | & f~x_{1}~\ldots~x_{n} & \mbox{(Function call)}\\
      & | & \emph{op}~a_{1}~\ldots~a_{n} & \mbox{(Operator call)} \\
    a & ::= & x & \mbox{(Simple argument)} \\
      & |   & (x_{1}, \ldots, x_{n}) & \mbox{(Tuple argument)} \\
      & |   & (\Fn{\tty}{p}{e}) & \mbox{(Function argument)}
  \end{array}
  $$

  \caption{Grammar for the core Futhark IR.  Some compiler stages may
    impose additional constraints on the structure of ASTs, in
    particular by requiring size annotations to be present, or banning
    certain operations.  The definition of $op$ in particular may
    differ between stages.  Some constructs, such as \lstinline{while}
    loops, have been elided for simplicity.  The elided constructs
    would have no influence on the development of the thesis.}
  \label{fig:futhark-ir}
\end{figure*}

\subsection{AST definition}

\Cref{fig:futhark-ir} shows the (simplified) core IR of Futhark, which
will be used for all compiler chapters of this thesis.  The syntax is
intentionally similar to the source language.  Notable details
include:
\begin{itemize}
\item Variable names are ranged over by $d$, $x$, $y$, and $z$, and we use
  $f$ to range over function names.
\item A variable may have a scalar type (i.e., \texttt{bool},
  \texttt{i32}, \texttt{f64}), or a multidimensional (regular) array
  type, such as $[][]\texttt{f64}$, which is the type of a matrix in
  which all rows have the same size.
\item Named and unnamed functions use a syntax similar to the source
  language, but unnamed functions may appear only as immediate
  arguments to SOACS, such as \lstinline{map}, \lstinline{reduce},
  \lstinline{filter}, and so on. Moreover, named functions may only be
  defined at top-level.  Recursion is not permitted.
\end{itemize}
When discussing properties of the language, we will often assume that
expressions ($e$) in the intermediate language are in A-normal
form~\cite{Sabry:1992:RPC:141478.141563}.  That is, all subexpressions
are variable names (except for the special cases \kw{loop}, \kw{if},
and \kw{let}).  However, for readability, we shall often stray from
strict A-normal form when showing examples.  Tuple-typed variables do
not exist in the IR, except as a syntactical construct for some
operators.  A let-bound pattern ($p$) consists of one or more
variables and associated types that bind the result of an expression
($e$); intuitively equivalent to a tuple pattern in the source
language.  Types are syntactically differentiated into two sorts:
$\tau$, without uniqueness attributes, and $\utau$, which permit an
optional uniqueness attribute (an asterisk).  Uniqueness attributes
are only used when specifying the parameter and return types of
top-level functions and \lstinline{for}-loops---patterns in
\lstinline{let} bindings and anonymous functions possess no uniqueness
attributes.

\subsubsection{Syntactic Conveniences}

We permit the omission of of \kw{in} immediately preceding \kw{let}.
This allows us to write
\begin{lstlisting}
let x = 2
let y = 3
in x + y
\end{lstlisting}
  instead of
\begin{lstlisting}
let x = 2 in
let y = 3 in
x + y
\end{lstlisting}
  which quickly adds up for larger expressions.  This convenience is
  also present in the Futhark source language.  For patterns in
  \kw{let}-bindings, we will also write
\[
  (x_{1}: \tau_{1}, \ldots, x_{n}: \tau_{n})
\]
instead of
\[
  (x_{1}: \tau_{1}) \ldots (x_{n}: \tau_{n})
\]
as strictly required by the syntax, in order to match the source
language.  For brevity, we will also sometimes elide some type
annotations.  In such cases we may also elide the parentheses when
only a single name is bound by the pattern.  We will often stray from
the strict syntax for lambdas, and write for example \lstinline{(+)}
for \lstinline{(\x y->x+y)}, or \lstinline{(+2)} instead of
\lstinline{(\x->x+2)}.

On occasion, we will need bind variables whose names we do not care
about.  In these cases we will use an underscore to indicate that the
name is irrelevant.  For example:
\begin{lstlisting}
map (\_ y _ -> x + 2) xs ys zs
\end{lstlisting}

\begin{figure}
\centering

\begin{tabular}{lp{58mm}}
  $\emph{op}~a_{1}~\ldots~a_{n}$ & Description \\ \hline
  \lstinline[mathescape]!size $c$ $x$! & Returns the size of dim $x$ of $x$, where $x$ must be a non-negative integer literal. \\
  \lstinline[mathescape]!iota $x$! & Returns the vector $[0,\ldots, x-1]$. \\
  \lstinline[mathescape]!replicate $y$ $x$! & Returns an array of rank one higher than $x$'s rank, containing an $y$-times replication of $x$.\\
  \lstinline[mathescape]!reshape ($y_{1},\ldots,y_{n}$) $x$! & Return an array of shape $y_{1}\times\ldots\times y_{n}$ containing the row-major elements of $x$.  It is a dynamic error if $x$ does not contain exactly $y_{1}\times\ldots\times y_{n}$ elements. \\
  \lstinline[mathescape]!rearrange ($c_{1}, \ldots, c_{n}$) $x$! & Rearrange the order of dimensions of the $n$-dimensional array $x$.  The reordering $c_{1}, \ldots, c_{n}$ must be a permutation of $1...n$. \\
\end{tabular}
\caption{Description of array operators.  SOACs are described on \cref{fig:soacDesc}}
\label{fig:arrayDesc}
\end{figure}

\begin{figure}
  \centering
\begin{tabular}{lp{80mm}}
  $\emph{op}~\nseq{a}{l}$ & Description \\ \hline
  \lstinline[mathescape]!map $\lambda$ $\nseq{x}{n}$! & Apply the $n$-ary function $\lambda$ simultaneously to consecutive elements of $x_{1}\ldots{}x_{n}$, producing an array of the results.  If $\lambda$ returns $k$ values, $k$ arrays are returned. \\
  \lstinline[mathescape]!scatter $x$ $y$ $z$! & For all $i$, write $z[i]$ to position $y[j]$ in $x$.  Consumes $x$ and semantically returns a new array.  The result is unspecified if different values are written to the same position.  Out-of-bound writes have no effect. \\
  \lstinline[mathescape]!reduce $\lambda$ ($\nseq{y}{n}$) $\nseq{x}{n}$! &
                                                                                               Perform a reduction of arrays $x_{1}, \ldots, x_{n}$ via the $2n$-ary function $\lambda$, producing $n$ values.  The values $y_{1}, \ldots, y_{n}$ constitute a neutral argument for $\lambda$.
  \\
  \lstinline[mathescape]!scan $\lambda$ ($\nseq{y}{n}$) $\nseq{x}{n}$! &
                                                                                             Perform an inclusive prefix scan of arrays $x_{1}, \ldots, x_{n}$ via the $2n$-ary function $\lambda$, producing $n$ values.  The values $y_{1}, \ldots, y_{n}$ constitute a neutral argument for $\lambda$. \\
  \lstinline[mathescape]!filter $\lambda$ $\nseq{x}{n}$! &
                                                                      Produce $n$ arrays, containing only those elements with index $j$ for which $\lambda~\nseq{x_{i}[j]}{n}$ is true. \\
  $\kw{stream\_map}~\lambda~\nseq{x}{n}$ & See \cref{sec:streaming-soacs}. \\
  $\kw{stream\_red}~\lambda_{c}~\lambda_{f}~\nseq{x}{n}$ & See \cref{sec:streaming-soacs}. \\
\end{tabular}
\caption{Description of SOAC operators.}
\label{fig:soacDesc}
\end{figure}


\begin{figure}[hbt]
\begin{tabular}{lcl}
\emph{op} & & \textrm{TySch}(\emph{op}) \\ \hline
  {\lstinline!size!} & : & $\forall\alpha.\texttt{i32} \rightarrow \alpha \rightarrow \texttt{i32}$ \\
  {\lstinline!iota!} & : & $\texttt{i32} \rightarrow []\texttt{i32}$ \\
  {\lstinline!replicate!} & : & $\forall\alpha.\texttt{i32} \rightarrow \alpha \rightarrow []\alpha$ \\
  \lstinline[mathescape]!reshape! & : & $\forall\alpha.(\texttt{i32}_{1}, \ldots, \texttt{i32}_{n})\rightarrow[]_{1}\cdots[]_{m}\alpha\rightarrow[]_{1}\cdots[]_{n}\alpha$ \\
  \lstinline[mathescape]!rearrange ($\nseq{c}{n}$)! & : & $\forall\alpha.[]_{1}\cdots[]_{n}\alpha\rightarrow[]_{1}\cdots[]_{n}\alpha$ \\
  {\lstinline!map!} & : & $\forall\nseq{\alpha}{n}\nseq{\beta}{m}.(\nseq{\alpha}{n} \rightarrow (\nseq{\beta}{m})) \rightarrow \nseq{[]\alpha_i}{n} \rightarrow (\nseq{\beta}{m})$ \\
  {\lstinline!scatter!} & : & $\forall \nseq{\alpha}{n}.(\nseq{[]\alpha_{i}}{n}) \rightarrow (\nseq{[]\texttt{i32}}{n}) \rightarrow (\nseq{[]\alpha_i}{n}) \rightarrow (\nseq{[]\beta_i}{n})$\\
  {\lstinline!reduce!} & : & $\forall\nseq{\alpha}{n}.(\nseq{\alpha}{n} \rightarrow \nseq{\alpha}{n} \rightarrow (\nseq{\alpha}{n})) \rightarrow (\nseq{\alpha}{n}) \rightarrow \nseq{[]\alpha_i}{n} \rightarrow (\nseq{\alpha}{n})$ \\
  {\lstinline!scan!} & : & $\forall\nseq{\alpha}{n}.(\nseq{\alpha}{n} \rightarrow \nseq{\alpha}{n} \rightarrow (\nseq{\alpha}{n})) \rightarrow (\nseq{\alpha}{n}) \rightarrow \nseq{[]\alpha_i}{n} \rightarrow (\nseq{[]\alpha_i}{n})$ \\
  {\lstinline!filter!} & : & $\forall\nseq{\alpha}{n}.(\nseq{\alpha}{n} \rightarrow \texttt{bool}) \rightarrow \nseq{[]\alpha_i}{n} \rightarrow (\nseq{[]\alpha_i}{n})$ \\
  \kw{stream\_map} & : & $\forall\nseq{\alpha}{n}~\nseq{\beta}{m}.(\nseq{[]\alpha_{i}}{n} \rightarrow (\nseq{[]\beta_{i}}{m})) \rightarrow \nseq{[]\alpha_i}{n} \rightarrow (\nseq{[]\beta}{m})$ \\
  \kw{stream\_red} & : & $\forall\nseq{\alpha}{n}~\nseq{\beta}{m}.(\nseq{\beta}{m} \rightarrow \nseq{\beta}{m} \rightarrow (\nseq{\beta}{m})) \rightarrow (\nseq{[]\alpha_{i}}{n} \rightarrow (\nseq{\beta_{i}}{m}))$ \\
  & & $~~~\rightarrow \nseq{[]\alpha_i}{n} \rightarrow (\nseq{\beta}{m})$ \\
\end{tabular}
\caption{Size-agnostic type schemes for operators, including various SOACs.}
\label{fig:soacType}
\end{figure}

\subsection{Array Operators}

An \textit{array operator} ($op$) is one of several constructs that
operate on arrays.  These include SOACs, but also such operations as
\lstinline{iota} and \lstinline{reshape}.  An array operator can be
applied to multiple arguments ($a$), where an argument can be a
variable in scope, but may also be a tuple of variables, or an
anonymous function.

For giving concise types to operators, we use a notion of \emph{extended
types} that supports polymorphism in types and for which arguments to
functions may themselves be functions:

\begin{tabular}{lrl}
$\etau$ & $::=$ & $\alpha~|~(\tau_{1}, \ldots, \tau_{n})~|~\etau_1 \rightarrow \etau_2~|~\etau \rightarrow \etau$ \\
$\opty$ & $::=$ & $\forall\seq{\alpha}.\etau$
\end{tabular}

\noindent Extended types ($\ubar{\tau}$) and extended type schemes
($\ubar{\sigma}$) are used only for the treatment of operators and we
shall be implicit about converting types and type schemes to and from
their extended counter parts.  We treat the single-element tuple
$(\tau)$ as equivalent to $\tau$.  A \emph{substitution} ($S$) is a
mapping from type variables (and, later, term variables) to extended
types.  We write substitutions $\langle x\mapsto y\rangle$.  Applying
a substitution $S$ to some object $B$, written $S(B)$, has the effect
of simultaneously applying $S$ to variables in $B$ (being the identity
outside its domain).  An extended type $\etau'$ is \emph{an instance
  of} an extended type scheme $\opty = \forall \vec{\alpha}.\etau$,
written $\opty \geq \etau'$, if there exists a substitution $S$ such
that $S(\etau) = \etau'$.

Type schemes for operators, including a representative subset of the
SOAC operators, are given in \cref{fig:soacType}, and an informal
description is given in \cref{fig:arrayDesc,fig:soacDesc}.  The SOACs
of the intermediate language (such as \lstinline{map}) are a
tuple-of-array versions of the user language SOACs. The SOACs of the
intermediate language receive an arbitrary number of array arguments
and produce a tuple of arrays as their result.  The semantics of a
SOAC operator can be intuitively understood as a composition between
\lstinline{unzip}, the user-language SOAC (such as \lstinline{map}),
and \lstinline{zip}, where the unnamed function is suitably modified
to work with the flat sequence of array arguments.

\subsection{Typing Rules}

In the type rules, we permit the implicit transformation of uniqueness
types and patterns $\utau/\utty/\hat{p}$ to their corresponding
$\tau/\tty/p$, where uniqueness attributes have simply been removed.
This simplifies the type rules, which can then be stated separate from
the rules for checking uniqueness properties.

Type environments ($\Gamma$) are finite maps from program variables to
types or function types.  Looking up the type of $x$ in $\Gamma$ is
written $\Gamma(x)$.  When $\Gamma$ is a type environment and $p$ is a
pattern $\tau_1~x_1,\cdots,\tau_n~x_n$, we write $\Gamma,p$ to denote
the typing environment $\Gamma,x_1:\tau_1,\cdots,x_n:\tau_n$.

Typing rules for the source language are given in
Figures~\ref{fig:srcTypeRules} and \ref{fig:srcTypeRulesExps}.  The
rules allow inferences among sentences of the following forms:

\begin{description}
\item[$\vdp p : \tty$,] read ``the pattern $p$ is matched by
  expressions of tuple type $\tty$.''
\item[$\vdhp \hat{p} : \utty$,] read ``the pattern with uniqueness
  $\hat{p}$ is matched by expressions of tuple type $\tty$.''
\item[$\Gamma \vda a : \tau / \ft$,] read ``under the assumptions
$\Gamma$, the operator argument $a$ has type $\tau$ or function type
$\ft$.''
\item[$\Gamma \vd b : \rho$,] read ``under the assumptions $\Gamma$,
  the expression $e$ has tuple type $\rho$.''
\item[$\Gamma \vdP P : \rho$,] read ``under the assumptions
$\Gamma$, the program $P$ has tuple type $\rho$.''
\end{description}

\begin{figure}[bt]
\sempart{Patterns}{\vdp p : \tty}

\fracc{}{\vdp (x_1: \tau_1, \cdots, x_n: \tau_n) : (\tau_1, \cdots, \tau_n)}

\sempart{Operator arguments}{\vda a : \tty / \ft}

\fracc{}{\Gamma \vda x : \Gamma(x)}

\fracc{\vdp p : \tty \sp \Gamma,p \vd b : \tty'}{\Gamma \vda \Fn{\tty'}{p}{b}: \tty \rightarrow \tty'}

\fracc{}{\vdp (x_1, \ldots, x_n) : (\Gamma(x_1), \ldots, \Gamma(x_n))}

\sempart{Parameters}{\vdhp \hat{p} : \utty}

\fracc{}{\vdhp (x_1: \utau_1, \cdots, x_n: \utau_n) : (\utau_1, \cdots, \utau_n)}

\sempart{Programs}{\Gamma \vdP P}

\fracc{\vdhp \hat{p} : (\tau_1, \ldots, \tau_n) \sp \Gamma,\hat{p} \vd e : \tty \\
\Gamma(f) = \tau_1 \rightarrow \ldots \rightarrow \tau_n \rightarrow \utty  \sp  \Gamma \vdP P}
{\Gamma \vdP \Fun{$f$}{$\hat{p}$}{$\utty$}{$e$}~P}

\fracc{}{\Gamma \vdP \epsilon}

\caption{Typing rules for Futhark's core IR, excluding expressions,
  which are shown on \cref{fig:srcTypeRulesExps}.}
\label{fig:srcTypeRules}
\end{figure}

\begin{figure}[bt]
\sempart{Expressions}{\Gamma \vd e : \rho}

\fracc{
  \vdp \hat{p} : \rho \sp \Gamma \vd e_1 : \rho \\
  \Gamma, p \vd e_2 : \rho'
}{
  \Gamma \vd \Let{p}{e_1}{e_2} : \rho'
}

\fracc{}{\Gamma \vd (x_1,\cdots,x_n) : (\Gamma(x_1),\cdots,\Gamma(x_n))}

\fracc{
  \Gamma(x) = []\tau \sp \Gamma(s) = \texttt{i32}
}{
  \Gamma \vd x[s] : \tau
}

\fracc{
  \textrm{ConstType}(\emph{ct}) = \tau
}{
  \Gamma \vd \emph{c} : \tau
}

\fracc{\Gamma \vda a_i : \etau_i \sp i \in \Set{1, \ldots, n}\\
  \textrm{TySch}(\emph{op}) \geq (\nseq{\etau}{n}) \rightarrow \rho
}{
  \Gamma \vd \emph{op}~\nseq{a}{n} : \rho
}

\fracc{
  \Gamma(x_i) = \tau_i \sp i \in \Set{1, \ldots, n} \\
  \textrm{lookup}_{\textrm{fun}}(f) = \tau_1 \rightarrow \cdots \rightarrow \tau_n \rightarrow \rho
}{
  \Gamma \vd f~x_{1}~\ldots~x_n : \rho
}

\fracc{
  \Gamma(s) = \texttt{bool} \sp \Gamma \vd e_1 : \rho \sp \Gamma \vd e_2 : \rho
}{
  \Gamma \vd \If{s}{e_1}{e_2} : \rho
}

\fracc{
  \vdp \hat{p} : \rho \sp \Gamma \vd e_1 : \rho \sp \Gamma \vd e_3 : \rho \\
  \Gamma \vd e_2 : \texttt{i32}
}{
  \Gamma \vd \Loop{\hat{p}}{e_1}{x}{e_2}{e_3} : \rho
}

\caption{Typing rules for expressions in Futhark's core IR.  The
  defition of TySch is found on \cref{fig:soacType}.}
\label{fig:srcTypeRulesExps}

\end{figure}

\fixme{Some rules are missing.}

\FloatBarrier
\section{Checking Uniqueness Types}
\label{sec:uniqueness-formalism}

An in-place update \lstinline{a with [i] <- v} is safe if and only if:

\begin{enumerate}
\item The array \texttt{a} (including aliases) does not occur on any
  execution path following the in-place update.
\item \texttt{v} does not alias \texttt{a}.
\end{enumerate}

To check for safety statically, we require two things: aliasing
information for all variables in the program
(\cref{sec:alias-analysis}), and a way to check for how and when
variables are used (\cref{sec:update-checking}).  In the formalisation
that follows, alias analysis is separate from safety checking.  In an
implementation, the two can be done in a single pass.

\subsection{Alias Analysis}
\label{sec:alias-analysis}

\newcommand{\expAliases}[3]{#1 \vdash #2 \Rightarrow #3}
\newcommand{\aliases}[1]{\textrm{aliases}(#1)}
\newcommand{\seqOccurences}[3]{#1 \gg #2 : #3}

We perform alias analysis on a program that we assume to be otherwise
type-correct.  Our presentation uses an inference rule-based approach
%similar to the one usually used for type systems.
in which the central judgment takes the form %as follows:
$\expAliases{\Sigma}{e}{\langle \sigma_{1}, \ldots, \sigma_{n}
  \rangle}$, which asserts that, within the context $\Sigma$, the
expression $e$ produces $n$ values, where value number $i$ has the
\textit{alias set} $\sigma_{i}$.  An alias set is a subset of the
variable names in scope, and indicates which variables an array value
(or variable) may be aliased with.
%(Alias sets for non-array variables are meaningless in this context).
The context $\Sigma$ maps variables in scope
to their aliasing sets.

\begin{figure}
\sempart{Expression aliases}{\expAliases{\Sigma}{e}{\langle \sigma_{1}, \ldots, \sigma_{n} \rangle}}

\begin{equation*}
\inference{
}{
  \expAliases{\Sigma}{(x_{1}, \ldots, x_{n})}{\langle \{ x_{1} \} \cup \Sigma(x_{1}), \ldots,  \{ x_{n} \} \cup \Sigma(x_{n}) \rangle}
}
\tagsc{Alias-Tuple}
\end{equation*}

\begin{equation*}
\inference{
  \expAliases{\Sigma}{e_{1}}{\langle \nseq{\sigma}{n} \rangle}
  \\
  \expAliases{\Sigma, x_{i} \mapsto \sigma_{i}}{e_{2}}{\langle \nseq{\sigma'}{n} \rangle}
}{
  \expAliases{\Sigma}{\Let{\nseq{(x:\tau)}{n}}{e_{1}}{e_{2}}}
  {\langle \nseq{\sigma'}{n} \rangle \setminus \{\nseq{x}{n}\}}
}
\tagsc{Alias-LetPat}
\end{equation*}

\begin{equation*}
\inference{
}{
  \expAliases{\Sigma}{k}{\langle \emptyset \rangle}
}
\tagsc{Alias-Const}
\end{equation*}

\begin{equation*}
\inference{
}{
  \expAliases{\Sigma}{x}{\langle \{ x \} \cup \Sigma(x) \rangle}
}
\tagsc{Alias-Var}
\end{equation*}

\begin{equation*}
\inference{
}{
  \expAliases{\Sigma}{x \odot y}{\langle \emptyset \rangle}
}
\tagsc{Alias-ScalarBinOp}
\end{equation*}

\begin{equation*}
\inference{
  \expAliases{\Sigma}{e_{2}}{\langle s^{2}_{1}, \ldots, s^{2}_{n}\rangle}
  &
  \expAliases{\Sigma}{e_{3}}{\langle s^{3}_{1}, \ldots, s^{3}_{n}\rangle}
}{
  \expAliases{\Sigma}{\text{\lstinline[mathescape]!if\ $x_{1}$ then\ $e_{2}$ else\ $e_{3}$!}}
  {\langle s^{2}_{1} \cup s^{3}_{1}, \ldots, s^{2}_{n} \cup s^{3}_{n}\rangle}
}
\tagsc{Alias-If}
\end{equation*}

\begin{equation*}
\inference{
  \textrm{$x$ is of rank $n$}
}{
  \expAliases{\Sigma}{\textsf{$x$[$\nseq{x}{n}$]}}{\langle \emptyset \rangle}
}
\tagsc{Alias-IndexArray}
\end{equation*}

\begin{equation*}
\inference{
  \textrm{$x$ is of rank $>n$}
}{
  \expAliases{\Sigma}{\textsf{$x$[$\nseq{x}{n}$]}}{\langle \{ x \} \cup \Sigma(x) \rangle}
}
\tagsc{Alias-SliceArray}
\end{equation*}

\begin{equation*}
\inference{
}{
\expAliases{\Sigma}{
  \text{\lstinline[mathescape]!$x_{a}$ with [$\nseq{e}{n}$] <-\ $e_{x}$!}
}{\langle \Set{x_{a}} \cup \Sigma(x_{a}) \rangle}
}
\tagsc{Alias-Update}
\end{equation*}

\caption{Aliasing rules for simple expressions.}
\label{fig:aliasing-rules-1}
\end{figure}

\fixme{only 1 parameter in loop case}
\fixme{only 1 return in apply case}
\begin{figure}
\sempart{Expression aliases (continued)}{\expAliases{\Sigma}{e}{\langle \sigma_{1}, \ldots, \sigma_{n} \rangle}}

\begin{equation*}
  \inference{
    \textrm{$\tau$ is not of form \texttt{*}$\tau'$}
    \\
    \expAliases{\Sigma}{x_{1}}{\langle \sigma \rangle}
    \sp
    \expAliases{\Sigma, x_{1} \mapsto \sigma}{e}{\langle \sigma' \rangle}
}{
\expAliases{\Sigma}
{\text{\lstinline[mathescape]!loop ($x_{1}: \tau$) =\ $y_{2}$ for\ $z_{1}$ <\ $z_{2}$ do\ $e$!}}
{\langle \sigma' \setminus \{x_{1}\} \rangle}
}\tagsc{Alias-DoLoop-Nonunique}
\end{equation*}

\begin{equation*}
  \inference{
}{
\expAliases{\Sigma}
{\text{\lstinline[mathescape]!loop ($x_{1}: \texttt{*}\tau$) =\ $y_{2}$ for\ $z_{1}$ <\ $z_{2}$ do\ $e$!}}
{\langle \emptyset  \rangle}
}\tagsc{Alias-DoLoop-Unique}
\end{equation*}

\begin{equation*}
\inference{
  \textrm{lookup}_{\textrm{fun}}(f) = \utau_{1}\rightarrow\cdots\rightarrow\utau_{n}\rightarrow\tau
  \\
  \expAliases{\Sigma}{x_{i}}{\langle \sigma_{i} \rangle}
  \quad
  \sigma = \bigcup_{\textrm{$\tau_{i}$ is not of form \texttt{*}$\tau'$}} \sigma_{i}
}{
  \expAliases{\Sigma}{\textsf{$f$ $x_{1}$ \ldots{} $x_{n}$}}
  {\langle \sigma \rangle}
}\tagsc{Alias-Apply-Nonunique}
\end{equation*}

\begin{equation*}
\inference{
  \textrm{lookup}_{\textrm{fun}}(f) = \utau_{1}\rightarrow\cdots\rightarrow\utau_{n}\rightarrow\texttt{*}\tau
}{
  \expAliases{\Sigma}{\textsf{$f$ $x_{1}$ \ldots{} $x_{n}$}}
  {\langle \emptyset \rangle}
}\tagsc{Alias-Apply-Unique}
\end{equation*}

\begin{equation*}
\inference{
}{
  \expAliases{\Sigma}{\kw{size}~c~x}{\langle \emptyset \rangle}
}\tagsc{Alias-Size}
\end{equation*}

\begin{equation*}
\inference{
}{
  \expAliases{\Sigma}{\text{\lstinline[mathescape]!iota\ $x$!}}{\langle \emptyset \rangle}
}\tagsc{Alias-Iota}
\end{equation*}

\begin{equation*}
\inference{
}{
  \expAliases{\Sigma}{\text{\lstinline[mathescape]!replicate\ $x$\ $y$!}}{\langle \emptyset \rangle}
}\tagsc{Alias-Replicate}
\end{equation*}

\begin{equation*}
  \inference{
    \expAliases{\Sigma}{y}{\sigma}
}{
  \expAliases{\Sigma}{\text{\lstinline[mathescape]!reshape\ $(x_{1},\ldots,x_{n})$\ $y$!}}{\langle \sigma \rangle}
}\tagsc{Alias-Reshape}
\end{equation*}

\begin{equation*}
\inference{
    \expAliases{\Sigma}{y}{\sigma}
}{
  \expAliases{\Sigma}{\text{\lstinline[mathescape]!rearrange\ ($c_{i},\ldots,c_{n}$)\ $y$!}}{\langle \sigma \rangle}
}\tagsc{Alias-Rearrange}
\end{equation*}

\begin{equation*}
\inference{
}{
  \expAliases{\Sigma}{\text{\lstinline[mathescape]!map ($\lambda p$:\ $(\nseq{\tau}{m}) \rightarrow e$)\ $\nseq{x}{n}$!}}
  {\langle \nseq{\emptyset}{m} \rangle}
}
\tagsc{Alias-Map}
\end{equation*}

\begin{equation*}
\inference{
}{
  \expAliases{\Sigma}{\kw{scatter}~x~y~z}
  {\langle \Set{x} \cup \Sigma(x) \rangle}
}
\tagsc{Alias-Scatter}
\end{equation*}

\begin{equation*}
\inference{
}{
  \expAliases{\Sigma}{\text{\lstinline[mathescape]!reduce\ $a$\ ($\nseq{x}{n}$)\ $\nseq{x}{n}$!}}
  {\langle \nseq{\emptyset}{n} \rangle}
}
\tagsc{Alias-Reduce}
\end{equation*}

\begin{equation*}
\inference{
}{
  \expAliases{\Sigma}{\text{\lstinline[mathescape]!scan\ $a$\ ($\nseq{x}{n}$)\ $\nseq{x}{n}$!}}
  {\langle \nseq{\emptyset}{n} \rangle}
}
\tagsc{Alias-Scan}
\end{equation*}

\begin{equation*}
\inference{
}{
  \expAliases{\Sigma}{\text{\lstinline[mathescape]!filter\ $a$\ $\nseq{x}{n}$!}}
  {\langle \nseq{\emptyset}{n} \rangle}
}
\tagsc{Alias-Filter}
\end{equation*}

\caption{More aliasing rules.}
\label{fig:aliasing-rules-2}
\end{figure}

The aliasing rules are listed in Figures~\ref{fig:aliasing-rules-1}
and \ref{fig:aliasing-rules-2}.  The \textsc{Alias-Var}-rule defines
the aliases of a variable expression to be the alias set of the
variable joined by the name of the variable itself - this is because
$v \notin \Sigma(v)$, as can be seen by \textsc{Alias-LetPat}.  Alias
sets for values produced by SOACs such as \kw{map} are empty.  We can
imagine the arrays produced as \textit{fresh}, although the compiler
is of course free to reuse memory if it can do so safely.  The
\textsc{Alias-IndexArray} rule tells us that a scalar read from an
array does not alias its origin array, but \textsc{Alias-SliceArray}
dictates that an array slice does.  This fits the our intuition of how
an implementation might implement these cases - scalars are read into
registers, where array slicing is just offsetting a pointer.

The most interesting aliasing rules are the ones for function calls
(\textsc{Alias-Apply-Nonunique} and \textsc{Alias-Apply-Unique}).
Since our alias analysis is intra-procedural, we are forced to be
conservative.  There are two rules, corresponding to functions
returning unique and non-unique arrays, respectively. When the result
is unique the alias set is empty, otherwise the result conservatively
aliases all non-unique parameters.

\subsection{In-Place Update Checking}
\label{sec:update-checking}

\newcommand{\inPlaceSafe}[3]{#1\ \rhd \langle #2, #3 \rangle}
\newcommand{\consumedOK}[3]{#1 \vdash #2 \triangle #3}

In our implementation, alias computation and in-place update checking
is performed at the same time, but is split here for expository
purposes.  In the following, let $\aliases{v}$ be the alias set of the
variable $v$, which we assume has been computed as in the previous
section.  We denote by $\mathcal{O}$ the set of the variables
\textit{observed} (used) in some expression $e$, and by $\mathcal{C}$
the set of variables \textit{consumed} through function calls and
in-place updates.  Together, the pair
$\langle\mathcal{C},\mathcal{O}\rangle$ is called an
\textit{occurrence trace}.

\Cref{fig:uniqueness-rules} defines a \textit{sequencing} judgment
between two occurrence traces, which takes the form
\[
  \seqOccurences
  {\langle\mathcal{C}_{1},\mathcal{O}_{1}\rangle}
  {\langle\mathcal{C}_{2},\mathcal{O}_{2}\rangle}
  {\langle\mathcal{C}_{3},\mathcal{O}_{3}\rangle}
\]
and which can be derived if and only if it is acceptable for
$\langle\mathcal{C}_{1},\mathcal{O}_{1}\rangle$ to happen first, then
$\langle\mathcal{C}_{2},\mathcal{O}_{2}\rangle$, giving the combined
occurrence trace $\langle\mathcal{C}_{3},\mathcal{O}_3\rangle$.  We
formulate this as a judgment because sequencing is sometimes not
derivable---for example in the case where an array is used after it
has been consumed.  The judgment is defined by a single inference
rule, which states that two occurrence traces can be sequentialized if
and only if no array consumed in the left-hand trace is used in the
right-hand trace.

Some of the most important inference rules for checking if an
expression $e$ is functionally safe with respect to in-place updates
are shown in \Cref{fig:uniqueness-rules}, where the central judgment
is $\inPlaceSafe{e}{\mathcal{C}}{\mathcal{O}}$.  We assume that the
program is in strict A-normal form.

The rule for in-place update %
\lstinline[mathescape]{$v_{a}$ with [$\nseq{v}{n}$] <- $v_{v}$}
%
gives rise to an occurrence trace indicating that we have
\textit{observed} $v_{v}$ and \textit{consumed} $v_{a}$.  Indices
$\nseq{v}{n}$ are ignored as they are necessarily scalar variables,
which cannot be consumed.

Another interesting rule concerns checking the safety of \kw{map}
expressions.  We do not wish to permit the function of a \kw{map} to
consume any array bound outside of it, as that would imply the array
may be consumed by more than one iteration of the \kw{map}.  However,
the function may consume its \textit{parameters}, which should be seen
as the \kw{map} expression as a whole consuming the corresponding
input array.  This restriction also preserves the parallel semantics
of \lstinline{map}, because different rows of a matrix can be safely
updated in parallel.  An example can be seen on
\Cref{fig:map-in-place-update}, which shows an in-place update nested
inside an array.  To express this restriction, we define an auxiliary
judgment:
\[
\consumedOK {\mathcal{P}}
{\langle\mathcal{C}_{1},\mathcal{O}_{1}\rangle}
{\langle\mathcal{C}_{2},\mathcal{O}_{2}\rangle}
\]
Here, $\mathcal{P}$ is a mapping from parameter names to alias sets.
Any variable $v$ in $\mathcal{O}_{1}$ that has a mapping in
$\mathcal{P}$ is replaced with $\mathcal{P}[v]$ to produce
$\mathcal{O}_{2}$.  If no such mapping exists, $v$ is simply included
in $\mathcal{O}_{2}$.  Similarly, any variable $v$ in
$\mathcal{C}_{1}$ that has a mapping in $\mathcal{P}$ is replaced with
the variables in the set $\mathcal{P}[v]$ (taking the union of all
such replacements), producing $\mathcal{C}_{2}$.  However, if $v$ does
not have such a mapping, the judgment is not derivable.
%This
%corresponds to the body of the function consuming something that is not
%a parameter.
%
The precise inference rules are shown on
\cref{fig:parameter-consumption}.
%
Do-loops and function declarations can be checked for safety in a
similar way.  A function is safe with respect to in-place updates if
its body consumes only those of the function's parameters that are
unique (rule \textsc{Safe-Fun} on \cref{fig:parameter-consumption}).
For a function call, care is taken to ensure that the argument passed
for a consumed parameter does not alias any other argument.

\begin{figure}
\sempart{Validity of sequencing}{\seqOccurences{\langle\mathcal{C}_{1},\mathcal{O}_{1}\rangle}{\langle\mathcal{C}_{2},\mathcal{O}_{2}\rangle}{\langle\mathcal{C}_{3},\mathcal{O}_{3}\rangle}}

\begin{equation*}
\inference{
  (\mathcal{O}_{2} \cup \mathcal{C}_{2}) \cap \mathcal{C}_{1} = \emptyset
}{
  \seqOccurences
  {\langle\mathcal{C}_{1},\mathcal{O}_{1}\rangle}
  {\langle\mathcal{C}_{2},\mathcal{O}_{2}\rangle}
  {\langle\mathcal{C}_{1}\cup\mathcal{C}_{2},\mathcal{O}_{1}\cup\mathcal{O}_{2}\rangle}
}\tagsc{Occurence-Seq}
\end{equation*}

\sempart{Uniqueness safety for expressions}{\inPlaceSafe{e}{\mathcal{C}}{\mathcal{O}}}

\begin{equation*}
\inference{
}{
\inPlaceSafe{v}{\emptyset}{\aliases{v}}
}
\tagsc{Safe-Var}
\end{equation*}

\begin{equation*}
\inference{
}{
\inPlaceSafe{k}{\emptyset}{\emptyset}
}
\tagsc{Safe-Const}
\end{equation*}

\begin{equation*}
\inference{
  \inPlaceSafe{e_{1}}{\mathcal{C}_{1}}{\mathcal{O}_{1}}
  &
  \inPlaceSafe{e_{2}}{\mathcal{C}_{2}}{\mathcal{O}_{2}}
  \\
  \seqOccurences
  {\langle\mathcal{C}_{1},\mathcal{O}_{1}\rangle}
  {\langle\mathcal{C}_{2},\mathcal{O}_{2}\rangle}
  {\langle\mathcal{C}_{3},\mathcal{O}_{3}\rangle}
}{
  \inPlaceSafe{\Let{v_{1}~\ldots~v_{n}}{e_{1}}{e_{2}}}
  {\mathcal{C}_{3}}{\mathcal{O}_{3}\rangle}
}
\tagsc{Safe-LetPat}
\end{equation*}

\begin{equation*}
\inference{
  \inPlaceSafe{v_{1}}{\mathcal{C}_{1}}{\mathcal{O}_{1}}
  &
  \inPlaceSafe{e_{2}}{\mathcal{C}_{2}}{\mathcal{O}_{2}}
  &
  \inPlaceSafe{e_{3}}{\mathcal{C}_{3}}{\mathcal{O}_{3}}
  \\
  \seqOccurences
  {\langle\mathcal{C}_{1},\mathcal{O}_{1}\rangle}
  {\langle\mathcal{C}_{2},\mathcal{O}_{2}\rangle}
  {\langle\mathcal{C}_{2}',\mathcal{O}_{2}'\rangle}
  \\
  \seqOccurences
  {\langle\mathcal{C}_{1},\mathcal{O}_{1}\rangle}
  {\langle\mathcal{C}_{3},\mathcal{O}_{3}\rangle}
  {\langle\mathcal{C}_{3}',\mathcal{O}_{3}'\rangle}
}{
  \inPlaceSafe{\text{\lstinline[mathescape]!if\ $v_{1}$ then\ $e_{2}$ else\ $e_{3}$!}}
  {\mathcal{C}'_{2}\cup\mathcal{C}'_{3}}
  {\mathcal{O}'_{2}\cup\mathcal{O}'_{3}}
}
\tagsc{Safe-If}
\end{equation*}

\begin{equation*}
\inference{
}{
  \inPlaceSafe{
    \text{\lstinline[mathescape]!$v_{a}$ with [$\nseq{v}{n}$] <- $v_{v}$!}
  }{\aliases{v_{a}}}{\aliases{v_{n}}}
}\tagsc{Safe-Update}
\end{equation*}

\begin{equation*}
\inference{
  \inPlaceSafe{e_{b}}{\mathcal{C}}{\mathcal{O}}
  \\
  \consumedOK
  {\nseq{p_{i} \mapsto \aliases{v_{i}}}{n}}
  {\langle\mathcal{C},\mathcal{O}\rangle}
  {\langle\mathcal{C}',\mathcal{O}'\rangle}
}{
  \inPlaceSafe
  {\text{\lstinline[mathescape]!map ($\fn\nseq{p}{n}$: $\nseq{t}{m} \rightarrow e_{b}$) $\nseq{v}{n}$!}}
  {\mathcal{C}'}{\mathcal{O}'}
}
\tagsc{Safe-Map}
\end{equation*}

\begin{equation*}
  \inference{
    \textrm{lookup}_{\textrm{fun}}(f) = \utau_{1}\rightarrow\cdots\rightarrow\utau_{n}\rightarrow\utau_{r}
    \\
    \forall i.(\utau_{i}=\texttt{*}\tau) \Rightarrow (\forall j.j = i \vee v \notin \aliases{v_{j}})
    \\
    \mathcal{C'} = \Set{\aliases{v_{i}}~|~v_{i}\in\nseq{v}{n}, x_{i} = v \wedge \tau_{i} = \texttt{*}\tau}
    \\
    \mathcal{O'} = \Set{\aliases{v_{i}}~|~v_{i}\in\nseq{v}{n}} - \mathcal{C'}
  }{
    \inPlaceSafe{\textsf{$f$ $x_{1}$ \ldots{} $x_{n}$}}
    {\mathcal{C}'}{\mathcal{O}'}
  }\tagsc{Safe-Fun}
\end{equation*}

\begin{equation*}
\inference{
  \inPlaceSafe{e}{\mathcal{C}}{\mathcal{O}}
  \\
  \forall v\in\mathcal{C}.\exists i.x_{i} = v \wedge.\utau_{i} = \texttt{*}\tau
  \\
  \forall i.(\utau_{i}=\texttt{*}\tau) \Rightarrow (\forall j.j = i \vee v \notin \aliases{v_{j}})
  \\
  \mathcal{C'} = \Set{\aliases{v_{i}}~|~v_{i}\in\nseq{v}{n}, x_{i} = v \wedge \tau_{i} = \texttt{*}\tau}
  \\
  \mathcal{O'} = \Set{\aliases{v_{i}}~|~v_{i}\in\nseq{v}{n}} - \mathcal{C'}
}{
  \inPlaceSafe{
    \text{\lstinline[mathescape]!loop ($\nseq{x_{i}: \utau_{i}}{n}$) =\ $\nseq{v}{n}$ for\ $z_{1}$ <\ $z_{2}$ do\ $e$!}}
  {\mathcal{C}'}{\mathcal{O}'}
}
\tagsc{Safe-Loop}
\end{equation*}

  \caption{Checking safety of consumption.}
  \label{fig:uniqueness-rules}
\end{figure}

\begin{figure}
\sempart{Uniqueness safety for function definitions}{\triangledown fun}

\begin{equation*}
  \inference{
    \inPlaceSafe{e}{\mathcal{C}}{\mathcal{O}}
    \\
    \forall v\in\mathcal{C}.\exists i.x_{i} = v \wedge \tau_{i} = \texttt{*}\tau
  }{
    \triangledown\Fun{$f$}{$\nseq{x_{i}: \hat{\tau}_{i}}{n}$}{$\utty_2$}{$e$}
  } \tagsc{Safe-Fun}
\end{equation*}

  \sempart{Validity of parameter consumption}{
\consumedOK {\mathcal{P}}
{\langle\mathcal{C}_{1},\mathcal{O}_{1}\rangle}
{\langle\mathcal{C}_{2},\mathcal{O}_{2}\rangle}}

\begin{equation*}
\boxed{
  \consumedOK
  {\mathcal{P}}
  {\langle\mathcal{C}_{1},\mathcal{O}_{1}\rangle}
  {\langle\mathcal{C}_{2},\mathcal{O}_{2}\rangle}
}
\end{equation*}

\begin{equation*}
\inference{
}{
\mathcal{P} \vdash \langle \emptyset, \emptyset \rangle \triangle \langle \emptyset, \emptyset \rangle
} \tagsc{Observe-BaseCase}
\end{equation*}

\begin{equation*}
\inference{
v \in \mathcal{P} \qquad \mathcal{P} \vdash \langle \emptyset, \mathcal{O} \rangle \triangle \langle \emptyset, \mathcal{O}' \rangle
}
{
\mathcal{P} \vdash \langle \emptyset, \{ v \} \cup \mathcal{O} \rangle \triangle \langle \emptyset, \mathcal{P}[v] \cup \mathcal{O}' \rangle
}\tagsc{Observe-Param}
\end{equation*}

\begin{equation*}
\inference{
\neg(v \in \mathcal{P}) \qquad \mathcal{P} \vdash \langle \emptyset, \mathcal{O} \rangle \triangle \langle \emptyset, \mathcal{O}' \rangle
}
{
\mathcal{P} \vdash \langle \emptyset, \{ v \} \cup \mathcal{O} \rangle \triangle \langle \emptyset, \{ v \} \cup \mathcal{O}' \rangle
}\tagsc{Observe-NonParam}
\end{equation*}

\begin{equation*}
\inference{
v \in \mathcal{P} \qquad \mathcal{P} \vdash \langle \mathcal{C}, \mathcal{O} \rangle \triangle \langle \mathcal{C}', \mathcal{O}' \rangle
}
{
\mathcal{P} \vdash \langle \{ v \} \cup \mathcal{C}, \mathcal{O} \rangle \triangle \langle \mathcal{P}[v] \cup \mathcal{C}', \mathcal{O}' \rangle
}\tagsc{Observe-NonParam}
\end{equation*}
  \caption{Checking parameter consumption.}
  \label{fig:parameter-consumption}
\end{figure}


\begin{figure}
\begin{lstlisting}
  -- This one is OK and considered to consume 'as'.
  let bs = map (\a -> a with [0] <- 2) as
  let d  = iota m
  -- This one is NOT safe, since d is not a formal parameter.
  let cs = map (\i -> d with [i] <- 2) (iota n)
\end{lstlisting}
  \caption{Examples of \lstinline{map}s with in-place updates.}
  \label{fig:map-in-place-update}
\end{figure}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
